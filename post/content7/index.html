<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AirflowのTaskFlowAPIについて | 467tn.com</title><meta name=keywords content="Airflow,Python"><meta name=description content="今更ですがしっかり調べてみました"><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b524e4b6d6a6efc25a7ca6b852c6483acb761f26eaea8f43a943a7adaf3dec55.css integrity="sha256-tSTkttam78JafKa4UsZIOst2Hybq6o9DqUOnra897FU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png><link rel=icon type=image/png sizes=16x16 href=https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png><link rel=icon type=image/png sizes=32x32 href=https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png><link rel=apple-touch-icon href=https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png><link rel=mask-icon href=https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="AirflowのTaskFlowAPIについて"><meta property="og:description" content="今更ですがしっかり調べてみました"><meta property="og:type" content="article"><meta property="og:url" content="https://467tn.com/post/content7/"><meta property="og:image" content="https://user-images.githubusercontent.com/60976262/191047722-dd7ed9ad-6e00-4b50-8073-24ae9602b8d6.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-01-01T11:30:03+00:00"><meta property="article:modified_time" content="2023-01-01T11:30:03+00:00"><meta property="og:site_name" content="467"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://user-images.githubusercontent.com/60976262/191047722-dd7ed9ad-6e00-4b50-8073-24ae9602b8d6.png"><meta name=twitter:title content="AirflowのTaskFlowAPIについて"><meta name=twitter:description content="今更ですがしっかり調べてみました"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://467tn.com/post/"},{"@type":"ListItem","position":3,"name":"AirflowのTaskFlowAPIについて","item":"https://467tn.com/post/content7/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AirflowのTaskFlowAPIについて","name":"AirflowのTaskFlowAPIについて","description":"今更ですがしっかり調べてみました","keywords":["Airflow","Python"],"articleBody":"TaskFlowAPIとは Airflow上でのWorkflowの書き方の一つ。従来Workflowの書き方は「DAGclassを定義し、Operator同士を繋げる書き方(Operatorを使用した書き方)」しかなかったが、Airflow2.0から新しい書き方が導入された。\n基本的な書き方 DAGの書き方 @dagでWorkflowを定義する関数をdecorateする。グローバル変数にDAGを登録する必要がなくなった。\n@dag( schedule=None, start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"), catchup=False, tags=[\"example\"], ) def tutorial_taskflow_api(): \"\"\" DAG Docs Example \"\"\"  tutorial_taskflow_apiがdag_id 関数配下に書いてある__doc__がDAGのDoc  Taskの書き方(PythonOperatorの例) TaskFlowDecoratorでTaskの関数をdecorateする。\n@task() def extract(): \"\"\" extract doc_md Example \"\"\" data_string = '{\"1001\": 301.27, \"1002\": 433.21, \"1003\": 502.22}' order_data_dict = json.loads(data_string) return order_data_dict  extractがtask_id 関数配下に書いてある__doc__がTaskのDoc  対応しているOperator 上記PythonOperator以外にも以下のOperatorがTaskFlowDecoratorに対応している。主に独自の実行環境でPythonを実行する必要があるようなOperatorが現在は対応しているイメージ。\n   Operator TaskFlowDecorator     PythonOperator @task(@task.python)   PythonVirtualenvOperator @task.virtualenv   BranchPythonOperator @task.branch   DockerOperator @task.docker   KubernetesOperator @task.kubernetes   ExternalPythonOperato @task.external_python   SensorOperator @task.sensor    Flowの書き方 Operatorを使用した書き方では、を使用してFlowを記述していたが、Pythonライクに関数を呼び出す形でFlow(依存関係)を書くことができるようになった。\n例えばデータを抽出(extract)して、抽出したデータを変換(transform)して、変換したデータからtotal_order_valueを読み込む(load)ような例は以下のように明示的に定義できる。\norder_data = extract() # extract order_summary = transform(order_data) # transform load(order_summary[\"total_order_value\"]) # load 何が異なるのか(TaskFlowAPIのメリット) Operatorを使用した書き方と比べ、個人的に以下の４点がメリットとしてあるかなと思っております。\n 「Xcomが抽象化されTask間のデータの受け渡しが容易になった」 「Task全体が見やすくなった」 「Taskを再利用できる」 「multiple_outputsが使える」  Xcomが抽象化されTask間のデータの受け渡しが容易になった 以前の書き方ではTask間のデータの受け渡しはtask_instancesのxcom_pullやxcom_pushなどを記述して行っていたが、Xcomが抽象化されたためXcomの記述をしなくても良くなり、データの受け渡しが容易になった。\n NOT TaskFlowAPI利用  def extract(**kwargs): ti = kwargs[\"ti\"] data_string = '{\"1001\": 301.27, \"1002\": 433.21, \"1003\": 502.22}' ti.xcom_push(\"order_data\", data_string) def transform(**kwargs): ti = kwargs[\"ti\"] extract_data_string = ti.xcom_pull(task_ids=\"extract\", key=\"order_data\") print(extract_data_string) extract_task = PythonOperator( task_id=\"extract\", python_callable=extract, ) transform_task = PythonOperator( task_id=\"transform\", python_callable=transform, ) extract_task  transform_task  TaskFlowAPI利用  @task() def extract(): data_string = '{\"1001\": 301.27, \"1002\": 433.21, \"1003\": 502.22}' order_data_dict = json.loads(data_string) return order_data_dict @task() def transform(order_data_dict: dict): print(order_data_dict) order_data = extract() transform(order_data) Task全体が見やすくなった DAGやTaskのDocがdecorateした関数の__doc__を自動的に参照してくれるようになったのでTask全体が見やすくなった。Task間の依存関係もわかりやすくなった。\n NOT TaskFlowAPI利用  def extract(**kwargs): pass extract_task = PythonOperator( task_id=\"extract\", python_callable=extract, ) extract_task.doc_md = dedent('extract_taskのdoc')  TaskFlowAPI利用  @task() def extract(): \"\"\" extract_taskのdoc \"\"\" Taskを再利用できる overrideという関数を使用して再利用できる。また再利用時にtask_id,queue,poolを指定できる。\nfrom airflow.decorators import task, dag from datetime import datetime @task def add_task(x, y): print(f\"Task args: x={x}, y={y}\") return x + y @dag(start_date=datetime(2022,1,1)) def mydag(): \"\"\" start - [add_start_0, add_start_1, add_start_2,] \"\"\" start = add_task.override(task_id='start')(1,2) for i in range(3): start  add_task.override(task_id=f'add_start_{i}')(start, i) @dag(start_date=datetime(2022,1,1)) def mydag2(): \"\"\" add_task  ['new_add_task_0', 'new_add_task_1', 'new_add_task_2'] \"\"\" start = add_task(1,2) for i in range(3): start  add_task.override(task_id=f'new_add_task_{i}')(start, i) first_dag = mydag() second_dag = mydag2() multiple_outputsが使える 1TaskでXcom複数のkey/valueをPushしたい時にこれまでkeyの分だけxcom_pushをしていたが、multiple_outputsを使えば1行で複数key/valueをPushすることができる。Taskの関数の戻り値にDictを指定しているとTaskFlowDecoratorに渡すmultiple_outputsが自動的にTrueになり、Dictを展開した上でXcomにkey/valueをPushしてくれる。\n NOT TaskFlowAPI利用  def identity_dict(**kwargs): ti = kwargs['ti'] ti.xcom_push('x', kwargs['x']) ti.xcom_push('y', kwargs['y'])  TaskFlowAPI利用  @task(multiple_outputs=True) def identity_dict(x: int, y: int): return {\"x\": x, \"y\": y} # 以下の書き方でも同じ挙動 @task def identity_dict(x: int, y: int) - dict[str, int]: return {\"x\": x, \"y\": y} 上記の場合は次のkey/valueがXcomにPushされる。\n return_value: {“x”: x, “y”: y} x: 1 y: 3  Operatorとの互換性について TaskFlowAPIとOperatorの併用は可能 @task() def extract_from_file(): order_data_file = \"/tmp/order_data.csv\" order_data_df = pd.read_csv(order_data_file) file_task = FileSensor(task_id='check_file', filepath='/tmp/order_data.csv') order_data = extract_from_file() file_task  order_data  Operator-TaskFlowAPIへのXcomの受け渡しもOperatorのoutputプロパティを利用すればできる  @task def task_output(msg): print(f\"Output: {msg}\") @dag(start_date=datetime(2022,1,1)) def mydag2(): bash_task = BashOperator( task_id=\"bash_task\", bash_command='echo \"Here is the message\"') bash_task_output = bash_task.output task_output(bash_task_output) TaskFlowAPIでもContextを取得することができる TaskにレンダリングされるContextは明示的に引数を渡すか(①)、kwargsでとるか(②)、get_current_contextを使用(③)して取得することができる。\n#　明示的に引数を渡す @task def my_python_callable(ti=None, next_ds=None): pass # kwargsでとる @task def my_python_callable(**kwargs): ti = kwargs[\"ti\"] next_ds = kwargs[\"next_ds\"] from airflow.operators.python import get_current_context def some_function_in_your_library(): context = get_current_context() ti = context[\"ti\"] @task.kubernetesを試してみる Zennにおいて以前書いた記事https://zenn.dev/467/articles/ca76be579ccf97に書いてあるOperator(KubernetesPodOperator)を使ったやり方をTaskFlowDecorator(@task.kubernetes)に対応しつつ試してみます。@task.kubernetesへ渡せるParameterはdecorators/__init__.pylから確認できます。\n簡易的なPodを作ってみる  dag  from airflow.decorators import task, dag from airflow.utils.dates import days_ago @task.kubernetes( namespace=\"default\", name=\"hello-pod-work\", image=\"python:3.8-slim-buster\", labels={\"foo\": \"bar\"}, do_xcom_push=False, in_cluster=False) def dry_run_demo(): print('dry_run_test') @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo() logとmanifestを確認するとわかるが、環境変数 __PYTHON_SCRIPTへdry_run_demo関数のコードをexportし、/tmp/script.pyという一時ファイルへ書き込み、実行ということをしている。\n manifest   env: - name: __PYTHON_SCRIPT value: \"import pickle\\nimport sys\\n\\n\\nif sys.version_info = (3,6):\\n try:\\n \\ from airflow.plugins_manager import integrate_macros_plugins\\n integrate_macros_plugins()\\n \\ except ImportError:\\n \\n pass\\n\\n\\narg_dict = {\\\"args\\\": [], \\\"kwargs\\\": {}}\\n\\n\\n# Script\\ndef dry_run_demo():\\n print('dry_run_test')\\n\\nres = dry_run_demo(*arg_dict[\\\"args\\\"], **arg_dict[\\\"kwargs\\\"])\"  log  [2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - + python -c 'import base64, os;x = os.environ[\"__PYTHON_SCRIPT\"];f = open(\"/tmp/script.py\", \"w\"); f.write(x); f.close()' [2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - + python /tmp/script.py [2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - dry_run_test Secretをmountしてみる  dag  from works import config_storage_apis @task.kubernetes( namespace=\"default\", name=\"hello-pod-work\", image=\"python:3.8-slim-buster\", labels={\"foo\": \"bar\"}, do_xcom_push=False, in_cluster=False, secrets=[ config_storage_apis.secret_file(), config_storage_apis.secret_env(), config_storage_apis.secret_all_keys()],) def dry_run_demo(): import os print(f\"secret_files: {os.listdir(path='/etc/sql_conn')}\") print(f\"secret_env: {os.environ.get('SQL_CONN')}\") print(f\"secret_all_keys: {os.environ.get('sql_alchemy_conn2')}\") @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo()  works.config_storage_apis  from airflow.kubernetes.secret import Secret def secret_file(): return Secret( deploy_type='volume', deploy_target='/etc/sql_conn', secret='airflow-secrets' ) def secret_env(): return Secret( deploy_type='env', deploy_target='SQL_CONN', secret='airflow-secrets', key='sql_alchemy_conn' ) def secret_all_keys(): return Secret( deploy_type='env', deploy_target=None, secret='airflow-secrets-2' )  log  [2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_files: ['sql_alchemy_conn', '..data', '..2023_01_03_05_20_34.2294851822'] [2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_env: hoge [2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_all_keys: hoge2 PersistentVolumeClaim(PVC)をmountしてみる  dag  from works import config_storage_apis @task.kubernetes( namespace=\"default\", name=\"hello-pod-work\", image=\"python:3.8-slim-buster\", labels={\"foo\": \"bar\"}, do_xcom_push=False, in_cluster=False, volumes=[config_storage_apis.volume()], volume_mounts=[config_storage_apis.volume_mount()],) def dry_run_demo(): import os print(f\"volume_mount: {os.listdir(path='/root/mount_file')}\") @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo()  works.config_storage_apis  from kubernetes.client import models as k8s def volume_mount(): return k8s.V1VolumeMount( mount_path='/root/mount_file', name='test-volume', read_only=True, sub_path=None, sub_path_expr=None, mount_propagation=None ) def volume(): return k8s.V1Volume( name='test-volume', persistent_volume_claim=k8s.V1PersistentVolumeClaimVolumeSource( claim_name='my-pvc'), )  log  [2023-01-03, 16:55:47 JST] {pod_manager.py:237} INFO - volume_mount: ['pv-delay-bind'] Configmapをmountしてみる  dag  from works import config_storage_apis @task.kubernetes( namespace=\"default\", name=\"hello-pod-work\", image=\"python:3.8-slim-buster\", labels={\"foo\": \"bar\"}, do_xcom_push=False, in_cluster=False, env_from=config_storage_apis.configmaps(),) def dry_run_demo(): import os print(f\"key1: {os.environ['key1']}\") print(f\"key2: {os.environ['key2']}\") @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo()  works.config_storage_apis   def configmaps(): return [ k8s.V1EnvFromSource( config_map_ref=k8s.V1ConfigMapEnvSource( name='test-configmap-1') ), k8s.V1EnvFromSource( config_map_ref=k8s.V1ConfigMapEnvSource( name='test-configmap-2') ), ]  log  [2023-01-03, 17:08:32 JST] {pod_manager.py:237} INFO - key1: value1 [2023-01-03, 17:08:32 JST] {pod_manager.py:237} INFO - key2: value2 Pod内に複数コンテナを作る Operatorを使用した書き方では複数コンテナを作る方法としてfull_pod_specパラメータを使用する方法とpod_template_fileパラメータを使用する方法がありましたが、TaskFlowDecoratorではfull_pod_specパラメータを使用する方法は現在サポートされていないようです。なのでpod_template_fileパラメータを使用する方法で試してみます。\n test.yml  apiVersion: v1 kind: Pod metadata: labels: run: share-pod name: share-pod spec: containers: - image: python:3.7-slim-buster name: container1 - image: python:3.8-slim-buster name: container2 restartPolicy: Always  dag  pod_template_filepath='test.yml' @task.kubernetes( namespace=\"default\", pod_template_file=pod_template_filepath, do_xcom_push=False, in_cluster=False,) def dry_run_demo(): print('hello container!') @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo() name:share-podへ、name:container1,name:container2というコンテナを作成しているが、dry_run_demo関数内のコード(print文)は一つのコンテナ上でしか実行されない。上記の例だとspec.containersの1要素目のコンテナ(container1)が優先されnameがbaseに変換された形で実行される。\n manifestの一部  apiVersion: v1 kind: Pod metadata: name: k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1 namespace: default spec: containers: - args: - -cx - python -c \"import base64, os;x = os.environ[\\\"__PYTHON_SCRIPT\\\"];f = open(\\\"/tmp/script.py\\\", \\\"w\\\"); f.write(x); f.close()\" \u0026\u0026 python /tmp/script.py command: - bash env: - name: __PYTHON_SCRIPT value: \"import pickle\\nimport sys\\n\\n\\nif sys.version_info = (3,6):\\n try:\\n \\ from airflow.plugins_manager import integrate_macros_plugins\\n integrate_macros_plugins()\\n \\ except ImportError:\\n \\n pass\\n\\n\\narg_dict = {\\\"args\\\": [], \\\"kwargs\\\": {}}\\n\\n\\n# Script\\ndef dry_run_demo():\\n print('hello container!')\\n\\nres = dry_run_demo(*arg_dict[\\\"args\\\"], **arg_dict[\\\"kwargs\\\"])\" image: python:3.7-slim-buster name: base - image: python:3.8-slim-buster name: container2  log(airlfow) airflowのlogにはbase(container1)のログしか残っていない  [2023-01-03, 18:42:40 JST] {pod_manager.py:237} INFO - hello container!  log(k8s) k8s上では正しく動作している。  $ k logs k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1 -c base + python -c 'import base64, os;x = os.environ[\"__PYTHON_SCRIPT\"];f = open(\"/tmp/script.py\", \"w\"); f.write(x); f.close()' + python /tmp/script.py $ k logs k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1 -c container2 Xcomを扱う  dag  @task.kubernetes( namespace=\"default\", name=\"hello-pod-work\", image=\"python:3.8-slim-buster\", labels={\"foo\": \"bar\"}, do_xcom_push=True, in_cluster=False,) def dry_run_demo(): f = open('/airflow/xcom/return.json', 'w') f.write('[1,2,3,4]') f.close() @task def xcom_output(**kwargs): ti = kwargs[\"ti\"] print(f\"output: {ti.xcom_pull(task_ids='dry_run_demo')}\") @dag( default_args={'owner': '467', 'depends_on_past': False}, start_date=days_ago(2), description='KubernetesPodOperatorを試す', tags=[\"work\"]) def test_kubernetes_pod_operator_work(): dry_run_demo()  xcom_output()  log(airflow xcom_output)  [2023-01-03, 19:14:54 JST] {logging_mixin.py:137} INFO - output: [1, 2, 3, 4] 参考  https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html  ","wordCount":"938","inLanguage":"en","image":"https://user-images.githubusercontent.com/60976262/191047722-dd7ed9ad-6e00-4b50-8073-24ae9602b8d6.png","datePublished":"2023-01-01T11:30:03Z","dateModified":"2023-01-01T11:30:03Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://467tn.com/post/content7/"},"publisher":{"@type":"Organization","name":"467tn.com","logo":{"@type":"ImageObject","url":"https://user-images.githubusercontent.com/60976262/190914441-404cb19b-540f-4178-a89d-8f89ab1e187c.png"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://467tn.com accesskey=h title="  (Alt + H)"><img src=https://467tn.com/home.png alt aria-label=logo height=35></a><div class=logo-switches></div></div><ul id=menu><li><a href=https://467tn.com/ title=whoami><span>whoami</span></a></li><li><a href=https://467tn.com/post/ title=post><span>post</span></a></li><li><a href=https://467tn.com/tags/ title=tags><span>tags</span></a></li><li><a href=https://filmarks.com/users/467 title=filmarks><span>filmarks</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://s6n.hatenablog.com/ title=travels><span>travels</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://zenn.dev/467 title=zenn><span>zenn</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://467tn.com>Home</a>&nbsp;»&nbsp;<a href=https://467tn.com/post/>Posts</a></div><h1 class=post-title>AirflowのTaskFlowAPIについて</h1><div class=post-description>今更ですがしっかり調べてみました</div><div class=post-meta><span title="2023-01-01 11:30:03 +0000 +0000">January 1, 2023</span>&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/srn221B/blog/tree/master/content/post/content7.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#taskflowapiとは>TaskFlowAPIとは</a></li><li><a href=#基本的な書き方>基本的な書き方</a><ul><li><a href=#dagの書き方>DAGの書き方</a></li><li><a href=#taskの書き方pythonoperatorの例>Taskの書き方(PythonOperatorの例)</a></li><li><a href=#対応しているoperator>対応しているOperator</a></li><li><a href=#flowの書き方>Flowの書き方</a></li></ul></li><li><a href=#何が異なるのかtaskflowapiのメリット>何が異なるのか(TaskFlowAPIのメリット)</a><ul><li><a href=#xcomが抽象化されtask間のデータの受け渡しが容易になった>Xcomが抽象化されTask間のデータの受け渡しが容易になった</a></li><li><a href=#task全体が見やすくなった>Task全体が見やすくなった</a></li><li><a href=#taskを再利用できる>Taskを再利用できる</a></li><li><a href=#multiple_outputsが使える>multiple_outputsが使える</a></li></ul></li><li><a href=#operatorとの互換性について>Operatorとの互換性について</a><ul><li><a href=#taskflowapiとoperatorの併用は可能>TaskFlowAPIとOperatorの併用は可能</a></li><li><a href=#taskflowapiでもcontextを取得することができる>TaskFlowAPIでもContextを取得することができる</a></li></ul></li><li><a href=#taskkubernetesを試してみる>@task.kubernetesを試してみる</a><ul><li><a href=#簡易的なpodを作ってみる>簡易的なPodを作ってみる</a></li><li><a href=#secretをmountしてみる>Secretをmountしてみる</a></li><li><a href=#persistentvolumeclaimpvcをmountしてみる>PersistentVolumeClaim(PVC)をmountしてみる</a></li><li><a href=#configmapをmountしてみる>Configmapをmountしてみる</a></li><li><a href=#pod内に複数コンテナを作る>Pod内に複数コンテナを作る</a></li><li><a href=#xcomを扱う>Xcomを扱う</a></li></ul></li><li><a href=#参考>参考</a></li></ul></nav></div></details></div><div class=post-content><h2 id=taskflowapiとは>TaskFlowAPIとは<a hidden class=anchor aria-hidden=true href=#taskflowapiとは>#</a></h2><p>Airflow上でのWorkflowの書き方の一つ。従来Workflowの書き方は「DAGclassを定義し、Operator同士を繋げる書き方(Operatorを使用した書き方)」しかなかったが、Airflow2.0から新しい書き方が導入された。</p><h2 id=基本的な書き方>基本的な書き方<a hidden class=anchor aria-hidden=true href=#基本的な書き方>#</a></h2><h3 id=dagの書き方>DAGの書き方<a hidden class=anchor aria-hidden=true href=#dagの書き方>#</a></h3><p><code>@dag</code>でWorkflowを定義する関数をdecorateする。グローバル変数にDAGを登録する必要がなくなった。</p><pre tabindex=0><code>@dag(
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=&#34;UTC&#34;),
    catchup=False,
    tags=[&#34;example&#34;],
)
def tutorial_taskflow_api():
   &#34;&#34;&#34; DAG Docs Example
   &#34;&#34;&#34;
</code></pre><ul><li><code>tutorial_taskflow_api</code>がdag_id</li><li>関数配下に書いてある__doc__がDAGのDoc</li></ul><h3 id=taskの書き方pythonoperatorの例>Taskの書き方(PythonOperatorの例)<a hidden class=anchor aria-hidden=true href=#taskの書き方pythonoperatorの例>#</a></h3><p>TaskFlowDecoratorでTaskの関数をdecorateする。</p><pre tabindex=0><code>@task()
def extract():
    &#34;&#34;&#34; extract doc_md Example
    &#34;&#34;&#34;
    data_string = &#39;{&#34;1001&#34;: 301.27, &#34;1002&#34;: 433.21, &#34;1003&#34;: 502.22}&#39;

    order_data_dict = json.loads(data_string)
    return order_data_dict
</code></pre><ul><li><code>extract</code>がtask_id</li><li>関数配下に書いてある__doc__がTaskのDoc</li></ul><h3 id=対応しているoperator>対応しているOperator<a hidden class=anchor aria-hidden=true href=#対応しているoperator>#</a></h3><p>上記PythonOperator以外にも以下のOperatorがTaskFlowDecoratorに対応している。主に独自の実行環境でPythonを実行する必要があるようなOperatorが現在は対応しているイメージ。</p><table><thead><tr><th>Operator</th><th>TaskFlowDecorator</th></tr></thead><tbody><tr><td>PythonOperator</td><td>@task(@task.python)</td></tr><tr><td>PythonVirtualenvOperator</td><td>@task.virtualenv</td></tr><tr><td>BranchPythonOperator</td><td>@task.branch</td></tr><tr><td>DockerOperator</td><td>@task.docker</td></tr><tr><td>KubernetesOperator</td><td>@task.kubernetes</td></tr><tr><td>ExternalPythonOperato</td><td>@task.external_python</td></tr><tr><td>SensorOperator</td><td>@task.sensor</td></tr></tbody></table><h3 id=flowの書き方>Flowの書き方<a hidden class=anchor aria-hidden=true href=#flowの書き方>#</a></h3><p>Operatorを使用した書き方では、<code>>></code>を使用してFlowを記述していたが、Pythonライクに関数を呼び出す形でFlow(依存関係)を書くことができるようになった。</p><p>例えばデータを抽出(extract)して、抽出したデータを変換(transform)して、変換したデータから<code>total_order_value</code>を読み込む(load)ような例は以下のように明示的に定義できる。</p><pre tabindex=0><code>order_data = extract() # extract
order_summary = transform(order_data) # transform
load(order_summary[&#34;total_order_value&#34;]) # load
</code></pre><h2 id=何が異なるのかtaskflowapiのメリット>何が異なるのか(TaskFlowAPIのメリット)<a hidden class=anchor aria-hidden=true href=#何が異なるのかtaskflowapiのメリット>#</a></h2><p>Operatorを使用した書き方と比べ、個人的に以下の４点がメリットとしてあるかなと思っております。</p><ul><li>「Xcomが抽象化されTask間のデータの受け渡しが容易になった」</li><li>「Task全体が見やすくなった」</li><li>「Taskを再利用できる」</li><li>「multiple_outputsが使える」</li></ul><h3 id=xcomが抽象化されtask間のデータの受け渡しが容易になった>Xcomが抽象化されTask間のデータの受け渡しが容易になった<a hidden class=anchor aria-hidden=true href=#xcomが抽象化されtask間のデータの受け渡しが容易になった>#</a></h3><p>以前の書き方ではTask間のデータの受け渡しは<a href=https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/models/taskinstance/index.html#module-airflow.models.taskinstance>task_instances</a>のxcom_pullやxcom_pushなどを記述して行っていたが、Xcomが抽象化されたためXcomの記述をしなくても良くなり、データの受け渡しが容易になった。</p><ul><li>NOT TaskFlowAPI利用</li></ul><pre tabindex=0><code>def extract(**kwargs):
    ti = kwargs[&#34;ti&#34;]
    data_string = &#39;{&#34;1001&#34;: 301.27, &#34;1002&#34;: 433.21, &#34;1003&#34;: 502.22}&#39;
    ti.xcom_push(&#34;order_data&#34;, data_string)
def transform(**kwargs):
    ti = kwargs[&#34;ti&#34;]
    extract_data_string = ti.xcom_pull(task_ids=&#34;extract&#34;, key=&#34;order_data&#34;)
    print(extract_data_string)
extract_task = PythonOperator(
    task_id=&#34;extract&#34;,
    python_callable=extract,
)
transform_task = PythonOperator(
    task_id=&#34;transform&#34;,
    python_callable=transform,
)
extract_task &gt;&gt; transform_task
</code></pre><ul><li>TaskFlowAPI利用</li></ul><pre tabindex=0><code>@task()
def extract():
    data_string = &#39;{&#34;1001&#34;: 301.27, &#34;1002&#34;: 433.21, &#34;1003&#34;: 502.22}&#39;
    order_data_dict = json.loads(data_string)
    return order_data_dict
@task()
def transform(order_data_dict: dict):
    print(order_data_dict)
order_data = extract()
transform(order_data)
</code></pre><h3 id=task全体が見やすくなった>Task全体が見やすくなった<a hidden class=anchor aria-hidden=true href=#task全体が見やすくなった>#</a></h3><p>DAGやTaskのDocがdecorateした関数の__doc__を自動的に参照してくれるようになったのでTask全体が見やすくなった。Task間の依存関係もわかりやすくなった。</p><ul><li>NOT TaskFlowAPI利用</li></ul><pre tabindex=0><code>def extract(**kwargs):
　　　pass
extract_task = PythonOperator(
  task_id=&#34;extract&#34;,
  python_callable=extract,
)
extract_task.doc_md = dedent(&#39;extract_taskのdoc&#39;)
</code></pre><ul><li>TaskFlowAPI利用</li></ul><pre tabindex=0><code>@task()
def extract():
  &#34;&#34;&#34; extract_taskのdoc
  &#34;&#34;&#34;
</code></pre><h3 id=taskを再利用できる>Taskを再利用できる<a hidden class=anchor aria-hidden=true href=#taskを再利用できる>#</a></h3><p><a href=https://github.com/apache/airflow/blob/81cd6c74788bc3182397dd28a4e7db3f21ff2d69/airflow/decorators/base.py#L447>override</a>という関数を使用して再利用できる。また再利用時にtask_id,queue,poolを指定できる。</p><pre tabindex=0><code>from airflow.decorators import task, dag
from datetime import datetime


@task
def add_task(x, y):
    print(f&#34;Task args: x={x}, y={y}&#34;)
    return x + y

@dag(start_date=datetime(2022,1,1))
def mydag():
    &#34;&#34;&#34; start -&gt; [add_start_0, add_start_1, add_start_2,]
    &#34;&#34;&#34;
    start = add_task.override(task_id=&#39;start&#39;)(1,2)
    for i in range(3):
        start &gt;&gt; add_task.override(task_id=f&#39;add_start_{i}&#39;)(start, i)


@dag(start_date=datetime(2022,1,1))
def mydag2():
    &#34;&#34;&#34; add_task &gt;&gt; [&#39;new_add_task_0&#39;, &#39;new_add_task_1&#39;, &#39;new_add_task_2&#39;]
    &#34;&#34;&#34;
    start = add_task(1,2)
    for i in range(3):
        start &gt;&gt; add_task.override(task_id=f&#39;new_add_task_{i}&#39;)(start, i)

first_dag = mydag()
second_dag = mydag2()
</code></pre><h3 id=multiple_outputsが使える>multiple_outputsが使える<a hidden class=anchor aria-hidden=true href=#multiple_outputsが使える>#</a></h3><p>1TaskでXcom複数のkey/valueをPushしたい時にこれまでkeyの分だけxcom_pushをしていたが、multiple_outputsを使えば1行で複数key/valueをPushすることができる。Taskの関数の戻り値にDictを指定しているとTaskFlowDecoratorに渡す<code>multiple_outputs</code>が自動的にTrueになり、Dictを展開した上でXcomにkey/valueをPushしてくれる。</p><ul><li>NOT TaskFlowAPI利用</li></ul><pre tabindex=0><code>def identity_dict(**kwargs):
    ti = kwargs[&#39;ti&#39;]
    ti.xcom_push(&#39;x&#39;, kwargs[&#39;x&#39;])
    ti.xcom_push(&#39;y&#39;, kwargs[&#39;y&#39;])
</code></pre><ul><li>TaskFlowAPI利用</li></ul><pre tabindex=0><code>@task(multiple_outputs=True)
def identity_dict(x: int, y: int):
    return {&#34;x&#34;: x, &#34;y&#34;: y}
# 以下の書き方でも同じ挙動
@task
def identity_dict(x: int, y: int) -&gt; dict[str, int]:
    return {&#34;x&#34;: x, &#34;y&#34;: y}
</code></pre><p>上記の場合は次のkey/valueがXcomにPushされる。</p><ul><li>return_value: {&ldquo;x&rdquo;: x, &ldquo;y&rdquo;: y}</li><li>x: 1</li><li>y: 3</li></ul><h2 id=operatorとの互換性について>Operatorとの互換性について<a hidden class=anchor aria-hidden=true href=#operatorとの互換性について>#</a></h2><h3 id=taskflowapiとoperatorの併用は可能>TaskFlowAPIとOperatorの併用は可能<a hidden class=anchor aria-hidden=true href=#taskflowapiとoperatorの併用は可能>#</a></h3><pre tabindex=0><code>@task()
def extract_from_file():
   order_data_file = &#34;/tmp/order_data.csv&#34;
   order_data_df = pd.read_csv(order_data_file)
file_task = FileSensor(task_id=&#39;check_file&#39;, filepath=&#39;/tmp/order_data.csv&#39;)
order_data = extract_from_file()
file_task &gt;&gt; order_data
</code></pre><ul><li>Operator->TaskFlowAPIへのXcomの受け渡しもOperatorの<code>output</code>プロパティを利用すればできる</li></ul><pre tabindex=0><code>@task
def task_output(msg):
    print(f&#34;Output: {msg}&#34;)

@dag(start_date=datetime(2022,1,1))
def mydag2():
    bash_task = BashOperator(
        task_id=&#34;bash_task&#34;,
        bash_command=&#39;echo &#34;Here is the message&#34;&#39;)
    bash_task_output = bash_task.output
    task_output(bash_task_output)
</code></pre><h3 id=taskflowapiでもcontextを取得することができる>TaskFlowAPIでもContextを取得することができる<a hidden class=anchor aria-hidden=true href=#taskflowapiでもcontextを取得することができる>#</a></h3><p>Taskにレンダリングされる<a href=https://github.com/apache/airflow/blob/8a15557f6fe73feab0e49f97b295160820ad7cfd/airflow/utils/context.py#L158>Context</a>は明示的に引数を渡すか(①)、kwargsでとるか(②)、get_current_contextを使用(③)して取得することができる。</p><pre tabindex=0><code>#　明示的に引数を渡す
@task
def my_python_callable(ti=None, next_ds=None):
    pass
# kwargsでとる
@task
def my_python_callable(**kwargs):
    ti = kwargs[&#34;ti&#34;]
    next_ds = kwargs[&#34;next_ds&#34;]

from airflow.operators.python import get_current_context
def some_function_in_your_library():
    context = get_current_context()
    ti = context[&#34;ti&#34;]
</code></pre><h2 id=taskkubernetesを試してみる>@task.kubernetesを試してみる<a hidden class=anchor aria-hidden=true href=#taskkubernetesを試してみる>#</a></h2><p>Zennにおいて以前書いた記事<a href=https://zenn.dev/467/articles/ca76be579ccf97>https://zenn.dev/467/articles/ca76be579ccf97</a>に書いてあるOperator(KubernetesPodOperator)を使ったやり方をTaskFlowDecorator(@task.kubernetes)に対応しつつ試してみます。@task.kubernetesへ渡せるParameterは<a href=https://github.com/apache/airflow/blob/5246c009c557b4f6bdf1cd62bf9b89a2da63f630/airflow/decorators/__init__.pyi#L300><code>decorators/__init__.pyl</code></a>から確認できます。</p><h3 id=簡易的なpodを作ってみる>簡易的なPodを作ってみる<a hidden class=anchor aria-hidden=true href=#簡易的なpodを作ってみる>#</a></h3><ul><li>dag</li></ul><pre tabindex=0><code>from airflow.decorators import task, dag
from airflow.utils.dates import days_ago

@task.kubernetes(
    namespace=&#34;default&#34;, name=&#34;hello-pod-work&#34;,
    image=&#34;python:3.8-slim-buster&#34;, labels={&#34;foo&#34;: &#34;bar&#34;}, do_xcom_push=False, in_cluster=False)
def dry_run_demo():
    print(&#39;dry_run_test&#39;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo()
</code></pre><p>logとmanifestを確認するとわかるが、環境変数<code> __PYTHON_SCRIPT</code>へdry_run_demo関数のコードをexportし、<code>/tmp/script.py</code>という一時ファイルへ書き込み、実行ということをしている。</p><ul><li>manifest</li></ul><pre tabindex=0><code>    env:
    - name: __PYTHON_SCRIPT
      value: &#34;import pickle\nimport sys\n\n\nif sys.version_info &gt;= (3,6):\n    try:\n
        \       from airflow.plugins_manager import integrate_macros_plugins\n        integrate_macros_plugins()\n
        \   except ImportError:\n        \n        pass\n\n\narg_dict = {\&#34;args\&#34;:
        [], \&#34;kwargs\&#34;: {}}\n\n\n# Script\ndef dry_run_demo():\n    print(&#39;dry_run_test&#39;)\n\nres = dry_run_demo(*arg_dict[\&#34;args\&#34;],
        **arg_dict[\&#34;kwargs\&#34;])&#34;
</code></pre><ul><li>log</li></ul><pre tabindex=0><code>[2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - + python -c &#39;import base64, os;x = os.environ[&#34;__PYTHON_SCRIPT&#34;];f = open(&#34;/tmp/script.py&#34;, &#34;w&#34;); f.write(x); f.close()&#39;
[2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - + python /tmp/script.py
[2023-01-03, 13:41:48 JST] {pod_manager.py:237} INFO - dry_run_test
</code></pre><h3 id=secretをmountしてみる>Secretをmountしてみる<a hidden class=anchor aria-hidden=true href=#secretをmountしてみる>#</a></h3><ul><li>dag</li></ul><pre tabindex=0><code>from works import config_storage_apis

@task.kubernetes(
    namespace=&#34;default&#34;, name=&#34;hello-pod-work&#34;, image=&#34;python:3.8-slim-buster&#34;,
    labels={&#34;foo&#34;: &#34;bar&#34;}, do_xcom_push=False, in_cluster=False,
    secrets=[
        config_storage_apis.secret_file(),
        config_storage_apis.secret_env(),
        config_storage_apis.secret_all_keys()],)
def dry_run_demo():
    import os
    print(f&#34;secret_files: {os.listdir(path=&#39;/etc/sql_conn&#39;)}&#34;)
    print(f&#34;secret_env: {os.environ.get(&#39;SQL_CONN&#39;)}&#34;)
    print(f&#34;secret_all_keys: {os.environ.get(&#39;sql_alchemy_conn2&#39;)}&#34;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo()
</code></pre><ul><li>works.config_storage_apis</li></ul><pre tabindex=0><code>from airflow.kubernetes.secret import Secret

def secret_file():
    return Secret(
        deploy_type=&#39;volume&#39;, deploy_target=&#39;/etc/sql_conn&#39;,
        secret=&#39;airflow-secrets&#39;
        )

def secret_env():
    return Secret(
        deploy_type=&#39;env&#39;, deploy_target=&#39;SQL_CONN&#39;,
        secret=&#39;airflow-secrets&#39;, key=&#39;sql_alchemy_conn&#39;
	)

def secret_all_keys():
    return Secret(
        deploy_type=&#39;env&#39;, deploy_target=None,
        secret=&#39;airflow-secrets-2&#39;
	)
</code></pre><ul><li>log</li></ul><pre tabindex=0><code>[2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_files: [&#39;sql_alchemy_conn&#39;, &#39;..data&#39;, &#39;..2023_01_03_05_20_34.2294851822&#39;]
[2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_env: hoge
[2023-01-03, 14:20:37 JST] {pod_manager.py:237} INFO - secret_all_keys: hoge2
</code></pre><h3 id=persistentvolumeclaimpvcをmountしてみる>PersistentVolumeClaim(PVC)をmountしてみる<a hidden class=anchor aria-hidden=true href=#persistentvolumeclaimpvcをmountしてみる>#</a></h3><ul><li>dag</li></ul><pre tabindex=0><code>from works import config_storage_apis

@task.kubernetes(
    namespace=&#34;default&#34;, name=&#34;hello-pod-work&#34;, image=&#34;python:3.8-slim-buster&#34;,
    labels={&#34;foo&#34;: &#34;bar&#34;}, do_xcom_push=False, in_cluster=False,
    volumes=[config_storage_apis.volume()],
    volume_mounts=[config_storage_apis.volume_mount()],)
def dry_run_demo():
    import os
    print(f&#34;volume_mount: {os.listdir(path=&#39;/root/mount_file&#39;)}&#34;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo()
</code></pre><ul><li>works.config_storage_apis</li></ul><pre tabindex=0><code>from kubernetes.client import models as k8s

def volume_mount():
    return k8s.V1VolumeMount(
        mount_path=&#39;/root/mount_file&#39;, name=&#39;test-volume&#39;,
        read_only=True, sub_path=None, sub_path_expr=None,
        mount_propagation=None
        )

def volume():
    return k8s.V1Volume(
        name=&#39;test-volume&#39;,
        persistent_volume_claim=k8s.V1PersistentVolumeClaimVolumeSource(
            claim_name=&#39;my-pvc&#39;),
        )
</code></pre><ul><li>log</li></ul><pre tabindex=0><code>[2023-01-03, 16:55:47 JST] {pod_manager.py:237} INFO - volume_mount: [&#39;pv-delay-bind&#39;]
</code></pre><h3 id=configmapをmountしてみる>Configmapをmountしてみる<a hidden class=anchor aria-hidden=true href=#configmapをmountしてみる>#</a></h3><ul><li>dag</li></ul><pre tabindex=0><code>from works import config_storage_apis

@task.kubernetes(
    namespace=&#34;default&#34;, name=&#34;hello-pod-work&#34;, image=&#34;python:3.8-slim-buster&#34;,
    labels={&#34;foo&#34;: &#34;bar&#34;}, do_xcom_push=False, in_cluster=False,
    env_from=config_storage_apis.configmaps(),)
def dry_run_demo():
    import os
    print(f&#34;key1: {os.environ[&#39;key1&#39;]}&#34;)
    print(f&#34;key2: {os.environ[&#39;key2&#39;]}&#34;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo()
</code></pre><ul><li>works.config_storage_apis</li></ul><pre tabindex=0><code>
def configmaps():
    return [
        k8s.V1EnvFromSource(
		config_map_ref=k8s.V1ConfigMapEnvSource(
			name=&#39;test-configmap-1&#39;)
		),
        k8s.V1EnvFromSource(
		config_map_ref=k8s.V1ConfigMapEnvSource(
			name=&#39;test-configmap-2&#39;)
		),
        ]
</code></pre><ul><li>log</li></ul><pre tabindex=0><code>[2023-01-03, 17:08:32 JST] {pod_manager.py:237} INFO - key1: value1
[2023-01-03, 17:08:32 JST] {pod_manager.py:237} INFO - key2: value2
</code></pre><h3 id=pod内に複数コンテナを作る>Pod内に複数コンテナを作る<a hidden class=anchor aria-hidden=true href=#pod内に複数コンテナを作る>#</a></h3><p>Operatorを使用した書き方では複数コンテナを作る方法として<code>full_pod_spec</code>パラメータを使用する方法と<code>pod_template_file</code>パラメータを使用する方法がありましたが、TaskFlowDecoratorでは<code>full_pod_spec</code>パラメータを使用する方法は現在サポートされていないようです。なので<code>pod_template_file</code>パラメータを使用する方法で試してみます。</p><ul><li>test.yml</li></ul><pre tabindex=0><code>apiVersion: v1
kind: Pod
metadata:
  labels:
    run: share-pod
  name: share-pod
spec:
  containers:
  - image: python:3.7-slim-buster
    name: container1
  - image: python:3.8-slim-buster
    name: container2
  restartPolicy: Always
</code></pre><ul><li>dag</li></ul><pre tabindex=0><code>pod_template_filepath=&#39;test.yml&#39;

@task.kubernetes(
    namespace=&#34;default&#34;, pod_template_file=pod_template_filepath,
    do_xcom_push=False, in_cluster=False,)
def dry_run_demo():
    print(&#39;hello container!&#39;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo()
</code></pre><p>name:share-podへ、name:container1,name:container2というコンテナを作成しているが、dry_run_demo関数内のコード(print文)は一つのコンテナ上でしか実行されない。上記の例だとspec.containersの1要素目のコンテナ(container1)が優先されnameが<code>base</code>に変換された形で実行される。</p><ul><li>manifestの一部</li></ul><pre tabindex=0><code>apiVersion: v1
kind: Pod
metadata:
  name: k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1
  namespace: default
spec:
  containers:
  - args:
    - -cx
    - python -c &#34;import base64, os;x = os.environ[\&#34;__PYTHON_SCRIPT\&#34;];f = open(\&#34;/tmp/script.py\&#34;,
      \&#34;w\&#34;); f.write(x); f.close()&#34; &amp;&amp; python /tmp/script.py
    command:
    - bash
    env:
    - name: __PYTHON_SCRIPT
      value: &#34;import pickle\nimport sys\n\n\nif sys.version_info &gt;= (3,6):\n    try:\n
        \       from airflow.plugins_manager import integrate_macros_plugins\n        integrate_macros_plugins()\n
        \   except ImportError:\n        \n        pass\n\n\narg_dict = {\&#34;args\&#34;:
        [], \&#34;kwargs\&#34;: {}}\n\n\n# Script\ndef dry_run_demo():\n    print(&#39;hello container!&#39;)\n\nres = dry_run_demo(*arg_dict[\&#34;args\&#34;],
        **arg_dict[\&#34;kwargs\&#34;])&#34;
    image: python:3.7-slim-buster
    name: base
  - image: python:3.8-slim-buster
    name: container2
</code></pre><ul><li>log(airlfow)
airflowのlogにはbase(container1)のログしか残っていない</li></ul><pre tabindex=0><code>[2023-01-03, 18:42:40 JST] {pod_manager.py:237} INFO - hello container!
</code></pre><ul><li>log(k8s)
k8s上では正しく動作している。</li></ul><pre tabindex=0><code>$ k logs k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1  -c base
+ python -c &#39;import base64, os;x = os.environ[&#34;__PYTHON_SCRIPT&#34;];f = open(&#34;/tmp/script.py&#34;, &#34;w&#34;); f.write(x); f.close()&#39;
+ python /tmp/script.py
$ k logs k8s-airflow-pod-3b69a29a430d46-eddb86a134094187bba374454c6d83f1  -c container2
</code></pre><h3 id=xcomを扱う>Xcomを扱う<a hidden class=anchor aria-hidden=true href=#xcomを扱う>#</a></h3><ul><li>dag</li></ul><pre tabindex=0><code>@task.kubernetes(
    namespace=&#34;default&#34;, name=&#34;hello-pod-work&#34;, image=&#34;python:3.8-slim-buster&#34;,
    labels={&#34;foo&#34;: &#34;bar&#34;}, do_xcom_push=True, in_cluster=False,)
def dry_run_demo():
    f = open(&#39;/airflow/xcom/return.json&#39;, &#39;w&#39;)
    f.write(&#39;[1,2,3,4]&#39;)
    f.close()

@task
def xcom_output(**kwargs):
    ti = kwargs[&#34;ti&#34;]
    print(f&#34;output: {ti.xcom_pull(task_ids=&#39;dry_run_demo&#39;)}&#34;)

@dag(
    default_args={&#39;owner&#39;: &#39;467&#39;, &#39;depends_on_past&#39;: False}, start_date=days_ago(2),
    description=&#39;KubernetesPodOperatorを試す&#39;, tags=[&#34;work&#34;])
def test_kubernetes_pod_operator_work():
    dry_run_demo() &gt;&gt; xcom_output()
</code></pre><ul><li>log(airflow xcom_output)</li></ul><pre tabindex=0><code>[2023-01-03, 19:14:54 JST] {logging_mixin.py:137} INFO - output: [1, 2, 3, 4]
</code></pre><h2 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h2><ul><li><a href=https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html>https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://467tn.com/tags/airflow/>Airflow</a></li><li><a href=https://467tn.com/tags/python/>Python</a></li></ul><nav class=paginav><a class=prev href=https://467tn.com/post/content8/><span class=title>« Prev</span><br><span>AirflowのPluginsについて</span></a>
<a class=next href=https://467tn.com/post/content6/><span class=title>Next »</span><br><span>Great Expectationsについて調べてみた</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share AirflowのTaskFlowAPIについて on twitter" href="https://twitter.com/intent/tweet/?text=Airflow%e3%81%aeTaskFlowAPI%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6&url=https%3a%2f%2f467tn.com%2fpost%2fcontent7%2f&hashtags=Airflow%2cPython"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://467tn.com>467tn.com</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>