[{"categories":["技術"],"contents":"こんにちは ブログ書くの久々すぎて書き方忘れた。。。うそです。\n去年の卒研終わったあたりから作り始めたこのサイトですが、あまりにも初期状態すぎたので、重い腰をあげて「HugoのthemaをBeautifulHugoからCupperに変更」「repositoryを整理」の２点をしました。一新したのでブログ書くモチベもこれで上がるはず（？）仕事もだいぶ慣れてきたので2022年は些細なことでももう少し書いていきたいな。。。\nタイトル通り 「Dockerを使ったGrafanaのDatasourceとDashboardの起動時追加方法」のメモを簡単に備忘録としてまとめておきます。\nDatasourceの起動時追加 Dashboardの起動時追加を設定する前に、まずはこっちを作っていきます。\n構成 . ├── docker-compose.yml ├── flask │ ├── Dockerfile │ └── app │ └── app.py ├── grafana │ ├── Dockerfile │ └── datasource.yml └── prometheus.yml ここでは grafanaで可視化するサーバーはprometheusで、prometheusでの監視はflaskを用いた自作exporterとしています。\nflask/Dockerfile FROM ubuntu:latest RUN apt-get update RUN apt-get install python3 python3-pip -y RUN pip3 install flask prometheus-client RUN mkdir /app flask/app.py pythonのPrometheusClientライブラリを使ってexporter化しましした。testしやすいようにcurl http://localhost:3000/hogeでGauge型のmetricsが増減するexporterです。\nfrom flask import Flask,render_template,request import json import queue from werkzeug.middleware.dispatcher import DispatcherMiddleware from prometheus_client import make_wsgi_app,Gauge app = Flask(__name__) G1 = Gauge(\u0026#39;Gauge1\u0026#39;,\u0026#39;Gauge test\u0026#39;) G2 = Gauge(\u0026#39;Gauge2\u0026#39;,\u0026#39;Gauge test\u0026#39;) @app.route(\u0026#39;/upG1\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def upG1(): G1.inc() return \u0026#34;upG1\u0026#34; @app.route(\u0026#39;/upG2\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def upG2(): G2.inc() return \u0026#34;upG2\u0026#34; @app.route(\u0026#39;/downG1\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def downG1(): G1.dec() return \u0026#34;downG1\u0026#34; @app.route(\u0026#39;/downG2\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def downG2(): G2.dec() return \u0026#34;downG2\u0026#34; app.wsgi_app = DispatcherMiddleware(app.wsgi_app, { \u0026#39;/metrics\u0026#39;: make_wsgi_app() }) if __name__ == \u0026#39;__main__\u0026#39;: G1.set(0) G2.set(0) app.run(host=\u0026#39;0.0.0.0\u0026#39;,port=5000) grafana/Dockerfile とりあえず最低限。\nFROM grafana/grafana:master COPY ./datasource.yml /etc/grafana/provisioning/datasources/ grafana/datasource.yml 起動時追加するdatasourceについて書きます。詳しいパラメータについてはGrafanaの公式ドキュメントに書いてあります。\ndatasources: - name: prometheus type: prometheus access: proxy url: \u0026#34;http://prometheus:9090\u0026#34; # 複数書きたい場合はこんな感じで #- name: prometheus # type: prometheus # access: proxy # url: \u0026#34;http://prometheus:9090\u0026#34; prometheus.yml 15秒間隔でexporterからmetricsを取得するように設定しています。\nglobal: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;flask:5000\u0026#39;] docker-compose.yml 上で書いていったものをまとめていきます。\nversion: \u0026#34;3\u0026#34; services: flask: build: ./flask command: python3 app/app.py volumes: - ./flask/app:/app ports: - 5000:5000 prometheus: image: prom/prometheus volumes: - ./prometheus.yml:/etc/prometheus/prometheus.yml ports: - 9090:9090 grafana: build: ./grafana ports: - 3000:3000 environment: - GF_SECURITY_ADMIN_PASSWORD=password - GF_USERS_ALLOW_SIGN_UP=false 起動確認 docker-compose buildとdocker-compose up -dを行って３つのコンテナが立ち上がっているのを確認した後、http://localhost:3000でGrafanaへ接続します。ID：admin、PASSWORD：passwordでsign inし、Configuration\u0026gt;Data SourcesにPrometheusがあれば完了です。\nDashboardの起動時追加方法について 上記DataSourceの起動時追加設定をした後に、進めていきます。\n構成 ├── docker-compose.yml ├── flask │ ├── Dockerfile │ └── app │ └── app.py ├── grafana │ ├── Dockerfile　#変更します │ ├── dashboard.yml　\u0008#作成します │ ├── datasource.yml　│ └── prometheus #作成します │ └── \u0026lt;hoge\u0026gt;.json　#作成します └── prometheus.yml dashboardの起動時追加設定ファイルdashboard.yml、dashboardの基盤ファイル\u0026lt;hoge\u0026gt;.jsonを作成し、それらファイルをコンテナへ置くためにgrafanaのDockerfileを変更します。\ngrafana/prometheus/.json http://localhost:3000でGrafanaへ接続し、 Create\u0026gt;Dashboardで起動時に追加したいDashboardの基盤ファイルを作っていきます。\nShare dashboard\u0026gt;Export\u0026gt;Save to fileでJSONファイルを出力し、./grafana/prometheus配下にファイルをおきます。 grafana/dashboard.yml 起動時追加するdashboardについて書きます。こちらも、詳しいパラメータについてはGrafanaの公式ドキュメントに書いてあります。\napiVersion: 1 providers: - name: \u0026#39;prometheus metrics\u0026#39; orgId: 1 folder: \u0026#39;\u0026#39; folderUid: \u0026#39;\u0026#39; type: file disableDeletion: false updateIntervalSeconds: 10 allowUiUpdates: false options: path: /etc/grafana/provisioning/dashboards/prometheus foldersFromFileStructure: true grafana/Dockerfile 作成したファイルをコンテナに置くために以下に変更。\nFROM grafana/grafana:master COPY ./datasource.yml /etc/grafana/provisioning/datasources/ COPY ./dashboard.yml /etc/grafana/provisioning/dashboards/ COPY ./prometheus /etc/grafana/provisioning/dashboards/prometheus 起動確認 DataSourceの設定した時と同じく、docker-compose buildとdocker-compose up -dを行って３つのコンテナが立ち上がっているのを確認した後、http://localhost:3000でGrafanaへ接続します。ID：admin、PASSWORD：passwordでsign inし、dashboardsが自動作成されていれば完了です。\n","permalink":"https://467tn.com/blog/content4/","tags":["Docker","Grafana","Prometheus","Flask"],"title":"Dockerを使ったGrafanaのDatasourceとDashboardの起動時追加方法"},{"categories":["技術",""],"contents":"タイトル通り。zeppelinからcassandraとsparkを使うまで簡単に構築メモ。 kubernetesとhelm 3.3.1を使って構築する。sparkとzeppelinのインストール→Cassandraのインストールの流れで説明。\nPod単位で弄れるが為だけにkubernetesを使います。Namespace分けたりIngress追加したりなどIaCならではの機能を活かした実装はここではしません。悪しからず。\nsparkとzeppelin  リポジトリはこれ デプロイすると、MasterPod1台、WorkerPod1台が動く。 Zepplin上のファイルはデフォルトで記憶される。  values.yamlにおいてServicePortの編集  デフォルトのままだとsparkWebUIとzeppelinのServicePortが競合する。なので、どちらかのServicePortを変更する。 ここではsparkWebUIのServicePortを8080から8081に変更する。  $ vim spark/values.yaml ... WebUi: Name: webui ServicePort: 8081 ContainerPort: 8080 ... インストール $ helm install spark ./spark インストール確認  defaultのnamespaceにインストールされていることを確認。  $ kubectl get pod spark-master-877d79587-shv7g 1/1 Running spark-worker-87d4579f4-7fsg4 1/1 Running spark-worker-87d4579f4-lb7ft 1/1 Running spark-worker-87d4579f4-tvcnb 1/1 Running spark-zeppelin-85d6c884d8-289mb 1/1 Running zeppelinとSparkWebUIにアクセスの確認  ブラウザ上からlocalhost:8080とlocalhost:8081へのアクセスへの確認ができれば完了。\n  cassandra  リポジトリはこれ user/passwordを設定しやすそうだったのでbitnamiを選択。  values.yamlにおいてuser/passwordの編集  デフォルトのままだとuserはcassandra、passwordはランダムで作られる。なので、指定したもので作られるように設定する。 ここではuserをcassandra、passwordをcassandraとする。  ... dbUser: user: cassandra forcePassword: false password: cassandra ... インストール $ helm install cassandra ./cassandra インストール確認  defaultのnamespaceにインストールされていることを確認。  $ kubectl get pod -n default cassandra-0 1/1 Running Zeppelin上のCassandraのInterpreter  zeppelinからcassandraへ接続する為の設定を変更。  cassandraが動いているClusterIPを確認 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE cassandra ClusterIP 10.99.62.208 \u0026lt;none\u0026gt; 9042/TCP,9160/TCP,8080/TCP 1d Interpreterの設定変更  ブラウザ上からhttp://localhost:8080/#/interpreterを開く。 上記で確認した情報を元にcassandra.credentials.password、cassandra.credentials.username、cassandra.host、cassandra.native.portの設定を変更。\n  完了確認 ","permalink":"https://467tn.com/blog/content3/","tags":["spark","zeppelin","kubernetes","cassandra"],"title":"zeppelinからcassandraとsparkを使う"},{"categories":["技術"],"contents":"前回に引き続きSpark環境構築系のおはなし。\nScala、何で開発してますか\nVScode，AtomなどのエディタやEclipse，NetBeansなどのIDE，開発内容によって様々だと思います。\n自分は簡単なコードだとScala(Metals)とScalaSnippetsの拡張機能を入れてVscodeを利用，Pluginを利用するものだったり複雑なコードだとIntelliJ IDEAを利用しています。\nSparkアプリケーションをIntelliJ IDEAで開発する方法がとても便利だったので記録に残しておきます。\n前提条件  Spark2.4がインストールされていること IntelliJIDEAがインストールされていること IntelliJIDEAでScalaを開発することができること Java8がインストールされていること JDK8を用いて開発できること\n（[File]=\u0026gt;[Project Structure\u0026hellip;]=\u0026gt;左カラムのSDKsを選択=\u0026gt;JDKhomepathを変更からJDKの追加はできます）  環境  OS：Mac Spark：2.4.5 IntelliJIDEA：2019.3  プロジェクト作成 Scala=\u0026gt;sbt でプロジェクトを作成します。\nName，Location：任意\nJDK：1.8\nsbt，Scala：現在安定して動くもの（ここではsbt1.2.8，Scala2.11.0）\n入力が終わったら[Finish]を押します。\nSparkを使えるようにする targetの配下にあるbuild.sbtにSparkのPluginを追加します。バージョンなどはMVNREPOSITORYサイトを参考にします。\nname := \u0026quot;sparktest\u0026quot; version := \u0026quot;0.1\u0026quot; scalaVersion := \u0026quot;2.11.0\u0026quot; libraryDependencies ++= Seq( \u0026quot;org.apache.spark\u0026quot; %% \u0026quot;spark-core\u0026quot; % \u0026quot;2.4.0\u0026quot;, \u0026quot;org.apache.spark\u0026quot; %% \u0026quot;spark-sql\u0026quot; % \u0026quot;2.4.0\u0026quot;, \u0026quot;org.apache.spark\u0026quot; %% \u0026quot;spark-mllib\u0026quot; % \u0026quot;2.4.3\u0026quot;, \u0026quot;org.apache.spark\u0026quot; %% \u0026quot;spark-graphx\u0026quot; % \u0026quot;2.4.0\u0026quot;, \u0026quot;org.apache.spark\u0026quot; %% \u0026quot;spark-streaming\u0026quot; % \u0026quot;2.4.0\u0026quot; ) 無事インポートが成功したらSpark環境は完了です。\nコーディング src=\u0026gt;main=\u0026gt;scalaを右クリック　New=\u0026gt;Scala Classで任意の名前[Class]を作成します。\nMain.scalaを編集します。ここではJSONファイルを単語集計したものをテキストファイルに保存するコードを書いていきます。\nimport org.apache.spark.{SparkConf, SparkContext} import com.fasterxml.jackson.databind.ObjectMapper import com.fasterxml.jackson.module.scala.DefaultScalaModule object example { def main(args: Array[String]): Unit = { // Sessionの生成  val conf = new SparkConf().setAppName(\u0026#34;appname\u0026#34;).setMaster(\u0026#34;local[*]\u0026#34;) val sc = new SparkContext(conf) val jsonLines = sc.parallelize(Array( \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Apple\u0026#34;,\u0026#34;num\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Orange\u0026#34;,\u0026#34;num\u0026#34;: 4}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Apple\u0026#34;,\u0026#34;num\u0026#34;: 2}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Peach\u0026#34;,\u0026#34;num\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34; )) val result = jsonLines.mapPartitions {lines =\u0026gt; //JSONのパーサを初期化  val mapper = new ObjectMapper() mapper.registerModule(DefaultScalaModule) //JSON文字列をパースし、\u0026#34;name\u0026#34;と\u0026#34;num\u0026#34;のペアで返却  lines.map {line =\u0026gt; val f = mapper.readValue(line,classOf[Map[String,String]]) (f(f\u0026#34;name\u0026#34;),f(\u0026#34;num\u0026#34;)) } } // savedirに集計結果を保存  result.saveAsTextFile(\u0026#34;savedir\u0026#34;) } } 実行 Terminal上でjarファイルを生成します。\n$ sbt package spark-submitを使って実行\n$ $SPARK_HOME/bin/spark-submit savedir上に集計結果が保存されていることを確認します。\n$ cat savedir_part* (Apple,1) (Orange,4) (Apple,2) (Peach,1) 終わり 実行毎にspark-submit〜と打つのは煩雑ですが、予測候補が出てくるのは開発する上での嬉しい＆助かる機能です🥰\n","permalink":"https://467tn.com/blog/content2/","tags":["spark","IntelliJIDEA"],"title":"IntelliJ IDEAでのSparkアプリケーション開発方法（Scala編）"},{"categories":["技術"],"contents":"今までpysparkをいじるときはコンソールでネチネチやっていたのですが、 pythonをjupyter-notebookで開発しているときに便利だなあと思ったので、思い切ってpysparkをいじるときもjupyter-notebookを使うようにしました。その時の備忘録。\n前提条件  Sparkがインストールされていること（この記事がわかりやすかったです。) jupyterがインストールされていること(pipまたはcondaでインストール)  環境  OS：Mac python：Python 3.7.6 Spark：2.4.5 jupyter-notebook：6.0.3  Sparkの設定 Spark上の環境ファイルのテンプレート(spark-env-sh.template)をコピーします。\n$ cd $SPARK_HOME/conf $ cp spark-env.sh.template spark-env.sh コピーしたファイルを書き換えていきます。\n$ vim spark-env.sh $ export PYSPARK_PYTHON=/usr/local/bin/python3 #pythonの場所 $ export PYSPARK_DRIVER_PYTHON=jupyter $ export PYSPARK_DRIVER_PYTHON_OPTS=\u0026quot;notebook\u0026quot; 環境変数の設定 以下の環境変数を.bashrc,.bash_profileに書きます。\nvim ~/.bashrc ... SPARK_HOME=#Sparkをインストールした場所 PATH=$SPARK_HOME/bin:$PATH ... 動作確認 早速、jupyterを使って簡単な演算を実装して見ます。\n$ pyspark http://localhost:8888/?token= *Token*が表示されます http://localhost:8888/loginを開きます。表示されたTokenを元にログインします。\nPythonファイルを作ります（New\u0026gt;python3）\n以下のようにsc(SparkSession)が使えていたら完了。\n終わり 快適な開発環境が整いました:heart_eyes:\n","permalink":"https://467tn.com/blog/content1/","tags":["pyspark","jupyter"],"title":"pysparkをjupyter-notebookから使う"}]