[{"categories":["技術"],"contents":"ブログ書かなさすぎて毎回hugoの使い方忘れた。 お久しぶりです。配属されて１年と２ヶ月（？）経ち、微妙に仕事が増えてきてここ最近は「つらー（＞＜）」って感じの毎日です、、ですが、なんとか楽しくやっております。\n４月に受験し5%足らず不合格となったCKA（CertifiedKubernetesAdministrator）を再受験しました。\nCKAとは、コンテナオーケストレーションシステム「Kubernetes」の試験の一つで、ハンズオン式の問題約20問を２時間で解く試験です。（kwsk https://www.cncf.io/certification/cka/） 同じ試験で、CKAD（Kubernetes Certified Application Developer）というのがありますが、CKADはアプリケーション開発者視点の問題が出題されるのに対し、CKAは管理者視点の問題が出題されます。\nそんな試験を再受験したのですが、なんとか合格できました。\n４月に不合格になってから何をしたのか、なんでしたのかetcを、ゆるくほぼ時系列で残しておきたいと思います。自分の記録代わりに余談も入れまくっていますが、ご容赦ください。\n何をしたのか ４月 不合格。ほぼ虚無。多分新しい仕事が始まって忙しくてKubernetes何もしていない。\n5月 「再受験しなきゃ」と思いながら何もしなかった。Talendに感動して戯れてた。\nお絵描きだいぶ描けるようになった（Talend） pic.twitter.com/UOWS4QxE0Q\n\u0026mdash; ４６７ (@srn221B) May 5, 2021  minikubeでクラスタたてて、Talendで使うためのPod/Service立てていたぐらい。 6月 肩こりがやばくなって、健康のために歩いていた。あと、めっちゃ湯船浸かった（治った）\n実績解除：家から3時間歩いてディズニー pic.twitter.com/aV1LcOSscf\n\u0026mdash; ４６７ (@srn221B) June 20, 2021  業務でJob/Cronjob/SecretとかPodの細かいオプション(.spec.restartPolicy/.spec.activeDeadlineSecondsあたり)いじってた。（※CKAではJob/Cronjobは範囲ではないです） 7月 ここら辺から「再受験しないとやばいなー」と思ってきた（n回目）ので、デッドライン8月末にして、しっかりと勉強スケジュールを立てた。\n模試/本試含め\nCKA特有の問題（KubeletのErrorとか、Kube-Controller-ManagerのErrorとか）が特にできなかった。\nことを思い出して、Kubernetes Componentのことわかっていなかったな〜となったので、Kubernetes Hardwayをやった。（あと、単純Kubernetesクラスタ環境自宅に欲しい！となったw）\n夏のイルミネーション2021になった pic.twitter.com/lb8Djr0cRT\n\u0026mdash; ４６７ (@srn221B) July 11, 2021  費用大体５万円ぐらいで１週間もしないでできたし、自分で各Componentの設定とかエラーハンドリングとかをすることで、かなり勉強になったし、個人的に一番良い対策になったんじゃないかなあと思ってます。ちなみに参考にさせていただいたサイトはこちら\n8月 問題あるごとにkubernetes.ioを見てって、kubernetesの操作が遅いよなあというか、操作に慣れてないよなあ\nと思ったので、前受験した時に購入したUdemyのコースをLabのみ一通り再度行った。期間は、夏季休暇含め大体10日とか\n またKubernetesの[チートシート](https://kubernetes.io/ja/docs/reference/kubectl/cheatsheet/)も読みながらできるだけ早く操作できるように意識した。 個人的に覚えておくといいものは以下ぐらい $ alias k=kubectl $ kubectl run \u0026lt;Podname\u0026gt; $ kubectl \u0026lt;run/create etc\u0026gt; -h $ kubectl auth can-i \u0026lt;create/get etc\u0026gt; --as=\u0026lt;User名/saだとsystem:serviceaccount:namespace:sa\u0026gt; 試験まであと１週間前ぐらいになって\nNetworkpolicy全然わかってねえ！ ということに気付き、\n kubernetes-network-policy-recipesを一通り見た。Networkpolicy動かすために自宅クラスタにNetworkPlugin入れたのですが、なぜか動かないので（調査中）脳内で解きました笑\nあと試験前日\n これも一通り見た。こちらは一部は実際に動かして解いてみたりしました。\nまとめる まとめると私がした対策は大きく分けると以下の３点です。\n Kubernetes Componentのことわかっていなかった  Kubernetes Hardwayをやった  なぜその作業が必要なのかを考えながら作業を行うようにする     kubectlの操作方法に慣れていなかった  UdemyのLabを一通りやって慣れる  チートシートを見ながらできるだけ効率的に行うようにする     Networkpolicy全然わかっていなかった  kubernetes-network-policy-recipesを一通り行う  問題文からEgress／Ingressどちらで構成すべきかを考えながら行うようにする      終わり まとめながら前不合格になったの完全に勉強不足が原因だったなあと（それはそう） CKA試験は１回目不合格だった場合はRetakeが無料で可能なので、今回特に損することなく２回目も受けられましたが、今度からはもっと準備できていない時とか自信ない時とかはリスケするとかちゃんとしようと思いました。笑\nひとまず受かってよかったです。試験の問題自体は、網羅していて難しすぎず易しすぎずな感じで楽しい\u0026amp;自宅から簡単に受験できるので、また期限切れになった時に再度受けてみたいと思います。あとCKADのチャレンジも！！\nでは\n","permalink":"https://467tn.com/blog/content5/","tags":["資格"],"title":"CKA受験記"},{"categories":["技術"],"contents":"こんにちは ブログ書くの久々すぎて書き方忘れた。。。うそです。\n去年の卒研終わったあたりから作り始めたこのサイトですが、あまりにも初期状態すぎたので、重い腰をあげて「HugoのthemaをBeautifulHugoからCupperに変更」「repositoryを整理」の２点をしました。一新したのでブログ書くモチベもこれで上がるはず（？）仕事もだいぶ慣れてきたので2022年は些細なことでももう少し書いていきたいな。。。\nタイトル通り 「Dockerを使ったGrafanaのDatasourceとDashboardの起動時追加方法」のメモを簡単に備忘録としてまとめておきます。\nDatasourceの起動時追加 Dashboardの起動時追加を設定する前に、まずはこっちを作っていきます。\n構成 . ├── docker-compose.yml ├── flask │ ├── Dockerfile │ └── app │ └── app.py ├── grafana │ ├── Dockerfile │ └── datasource.yml └── prometheus.yml ここでは grafanaで可視化するサーバーはprometheusで、prometheusでの監視はflaskを用いた自作exporterとしています。\nflask/Dockerfile FROM ubuntu:latest RUN apt-get update RUN apt-get install python3 python3-pip -y RUN pip3 install flask prometheus-client RUN mkdir /app flask/app.py pythonのPrometheusClientライブラリを使ってexporter化しましした。testしやすいようにcurl http://localhost:3000/hogeでGauge型のmetricsが増減するexporterです。\nfrom flask import Flask,render_template,request import json import queue from werkzeug.middleware.dispatcher import DispatcherMiddleware from prometheus_client import make_wsgi_app,Gauge app = Flask(__name__) G1 = Gauge(\u0026#39;Gauge1\u0026#39;,\u0026#39;Gauge test\u0026#39;) G2 = Gauge(\u0026#39;Gauge2\u0026#39;,\u0026#39;Gauge test\u0026#39;) @app.route(\u0026#39;/upG1\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def upG1(): G1.inc() return \u0026#34;upG1\u0026#34; @app.route(\u0026#39;/upG2\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def upG2(): G2.inc() return \u0026#34;upG2\u0026#34; @app.route(\u0026#39;/downG1\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def downG1(): G1.dec() return \u0026#34;downG1\u0026#34; @app.route(\u0026#39;/downG2\u0026#39;,methods=[\u0026#34;GET\u0026#34;]) def downG2(): G2.dec() return \u0026#34;downG2\u0026#34; app.wsgi_app = DispatcherMiddleware(app.wsgi_app, { \u0026#39;/metrics\u0026#39;: make_wsgi_app() }) if __name__ == \u0026#39;__main__\u0026#39;: G1.set(0) G2.set(0) app.run(host=\u0026#39;0.0.0.0\u0026#39;,port=5000) grafana/Dockerfile とりあえず最低限。\nFROM grafana/grafana:master COPY ./datasource.yml /etc/grafana/provisioning/datasources/ grafana/datasource.yml 起動時追加するdatasourceについて書きます。詳しいパラメータについてはGrafanaの公式ドキュメントに書いてあります。\ndatasources: - name: prometheus type: prometheus access: proxy url: \u0026#34;http://prometheus:9090\u0026#34; # 複数書きたい場合はこんな感じで #- name: prometheus # type: prometheus # access: proxy # url: \u0026#34;http://prometheus:9090\u0026#34; prometheus.yml 15秒間隔でexporterからmetricsを取得するように設定しています。\nglobal: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;flask:5000\u0026#39;] docker-compose.yml 上で書いていったものをまとめていきます。\nversion: \u0026#34;3\u0026#34; services: flask: build: ./flask command: python3 app/app.py volumes: - ./flask/app:/app ports: - 5000:5000 prometheus: image: prom/prometheus volumes: - ./prometheus.yml:/etc/prometheus/prometheus.yml ports: - 9090:9090 grafana: build: ./grafana ports: - 3000:3000 environment: - GF_SECURITY_ADMIN_PASSWORD=password - GF_USERS_ALLOW_SIGN_UP=false 起動確認 docker-compose buildとdocker-compose up -dを行って３つのコンテナが立ち上がっているのを確認した後、http://localhost:3000でGrafanaへ接続します。ID：admin、PASSWORD：passwordでsign inし、Configuration\u0026gt;Data SourcesにPrometheusがあれば完了です。\nDashboardの起動時追加方法について 上記DataSourceの起動時追加設定をした後に、進めていきます。\n構成 ├── docker-compose.yml ├── flask │ ├── Dockerfile │ └── app │ └── app.py ├── grafana │ ├── Dockerfile　#変更します │ ├── dashboard.yml　\u0008#作成します │ ├── datasource.yml　│ └── prometheus #作成します │ └── \u0026lt;hoge\u0026gt;.json　#作成します └── prometheus.yml dashboardの起動時追加設定ファイルdashboard.yml、dashboardの基盤ファイル\u0026lt;hoge\u0026gt;.jsonを作成し、それらファイルをコンテナへ置くためにgrafanaのDockerfileを変更します。\ngrafana/prometheus/.json http://localhost:3000でGrafanaへ接続し、 Create\u0026gt;Dashboardで起動時に追加したいDashboardの基盤ファイルを作っていきます。\nShare dashboard\u0026gt;Export\u0026gt;Save to fileでJSONファイルを出力し、./grafana/prometheus配下にファイルをおきます。 grafana/dashboard.yml 起動時追加するdashboardについて書きます。こちらも、詳しいパラメータについてはGrafanaの公式ドキュメントに書いてあります。\napiVersion: 1 providers: - name: \u0026#39;prometheus metrics\u0026#39; orgId: 1 folder: \u0026#39;\u0026#39; folderUid: \u0026#39;\u0026#39; type: file disableDeletion: false updateIntervalSeconds: 10 allowUiUpdates: false options: path: /etc/grafana/provisioning/dashboards/prometheus foldersFromFileStructure: true grafana/Dockerfile 作成したファイルをコンテナに置くために以下に変更。\nFROM grafana/grafana:master COPY ./datasource.yml /etc/grafana/provisioning/datasources/ COPY ./dashboard.yml /etc/grafana/provisioning/dashboards/ COPY ./prometheus /etc/grafana/provisioning/dashboards/prometheus 起動確認 DataSourceの設定した時と同じく、docker-compose buildとdocker-compose up -dを行って３つのコンテナが立ち上がっているのを確認した後、http://localhost:3000でGrafanaへ接続します。ID：admin、PASSWORD：passwordでsign inし、dashboardsが自動作成されていれば完了です。\n","permalink":"https://467tn.com/blog/content4/","tags":["Docker","Grafana","Prometheus","Flask"],"title":"Dockerを使ったGrafanaのDatasourceとDashboardの起動時追加方法"},{"categories":["技術",""],"contents":"タイトル通り。zeppelinからcassandraとsparkを使うまで簡単に構築メモ。 kubernetesとhelm 3.3.1を使って構築する。sparkとzeppelinのインストール→Cassandraのインストールの流れで説明。\nPod単位で弄れるが為だけにkubernetesを使います。Namespace分けたりIngress追加したりなどIaCならではの機能を活かした実装はここではしません。悪しからず。\nsparkとzeppelin  リポジトリはこれ デプロイすると、MasterPod1台、WorkerPod1台が動く。 Zepplin上のファイルはデフォルトで記憶される。  values.yamlにおいてServicePortの編集  デフォルトのままだとsparkWebUIとzeppelinのServicePortが競合する。なので、どちらかのServicePortを変更する。 ここではsparkWebUIのServicePortを8080から8081に変更する。  $ vim spark/values.yaml ... WebUi: Name: webui ServicePort: 8081 ContainerPort: 8080 ... インストール $ helm install spark ./spark インストール確認  defaultのnamespaceにインストールされていることを確認。  $ kubectl get pod spark-master-877d79587-shv7g 1/1 Running spark-worker-87d4579f4-7fsg4 1/1 Running spark-worker-87d4579f4-lb7ft 1/1 Running spark-worker-87d4579f4-tvcnb 1/1 Running spark-zeppelin-85d6c884d8-289mb 1/1 Running zeppelinとSparkWebUIにアクセスの確認  ブラウザ上からlocalhost:8080とlocalhost:8081へのアクセスへの確認ができれば完了。\n  cassandra  リポジトリはこれ user/passwordを設定しやすそうだったのでbitnamiを選択。  values.yamlにおいてuser/passwordの編集  デフォルトのままだとuserはcassandra、passwordはランダムで作られる。なので、指定したもので作られるように設定する。 ここではuserをcassandra、passwordをcassandraとする。  ... dbUser: user: cassandra forcePassword: false password: cassandra ... インストール $ helm install cassandra ./cassandra インストール確認  defaultのnamespaceにインストールされていることを確認。  $ kubectl get pod -n default cassandra-0 1/1 Running Zeppelin上のCassandraのInterpreter  zeppelinからcassandraへ接続する為の設定を変更。  cassandraが動いているClusterIPを確認 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE cassandra ClusterIP 10.99.62.208 \u0026lt;none\u0026gt; 9042/TCP,9160/TCP,8080/TCP 1d Interpreterの設定変更  ブラウザ上からhttp://localhost:8080/#/interpreterを開く。 上記で確認した情報を元にcassandra.credentials.password、cassandra.credentials.username、cassandra.host、cassandra.native.portの設定を変更。\n  完了確認 ","permalink":"https://467tn.com/blog/content3/","tags":["spark","zeppelin","kubernetes","cassandra"],"title":"zeppelinからcassandraとsparkを使う"},{"categories":["技術"],"contents":"前回に引き続きSpark環境構築系のおはなし。\nScala、何で開発してますか\nVScode，AtomなどのエディタやEclipse，NetBeansなどのIDE，開発内容によって様々だと思います。\n自分は簡単なコードだとScala(Metals)とScalaSnippetsの拡張機能を入れてVscodeを利用，Pluginを利用するものだったり複雑なコードだとIntelliJ IDEAを利用しています。\nSparkアプリケーションをIntelliJ IDEAで開発する方法がとても便利だったので記録に残しておきます。\n前提条件  Spark2.4がインストールされていること IntelliJIDEAがインストールされていること IntelliJIDEAでScalaを開発することができること Java8がインストールされていること JDK8を用いて開発できること\n（[File]=\u0026gt;[Project Structure\u0026hellip;]=\u0026gt;左カラムのSDKsを選択=\u0026gt;JDKhomepathを変更からJDKの追加はできます）  環境  OS：Mac Spark：2.4.5 IntelliJIDEA：2019.3  プロジェクト作成 Scala=\u0026gt;sbt でプロジェクトを作成します。\nName，Location：任意\nJDK：1.8\nsbt，Scala：現在安定して動くもの（ここではsbt1.2.8，Scala2.11.0）\n入力が終わったら[Finish]を押します。\nSparkを使えるようにする targetの配下にあるbuild.sbtにSparkのPluginを追加します。バージョンなどはMVNREPOSITORYサイトを参考にします。\nname := \u0026#34;sparktest\u0026#34; version := \u0026#34;0.1\u0026#34; scalaVersion := \u0026#34;2.11.0\u0026#34; libraryDependencies ++= Seq( \u0026#34;org.apache.spark\u0026#34; %% \u0026#34;spark-core\u0026#34; % \u0026#34;2.4.0\u0026#34;, \u0026#34;org.apache.spark\u0026#34; %% \u0026#34;spark-sql\u0026#34; % \u0026#34;2.4.0\u0026#34;, \u0026#34;org.apache.spark\u0026#34; %% \u0026#34;spark-mllib\u0026#34; % \u0026#34;2.4.3\u0026#34;, \u0026#34;org.apache.spark\u0026#34; %% \u0026#34;spark-graphx\u0026#34; % \u0026#34;2.4.0\u0026#34;, \u0026#34;org.apache.spark\u0026#34; %% \u0026#34;spark-streaming\u0026#34; % \u0026#34;2.4.0\u0026#34; ) 無事インポートが成功したらSpark環境は完了です。\nコーディング src=\u0026gt;main=\u0026gt;scalaを右クリック　New=\u0026gt;Scala Classで任意の名前[Class]を作成します。\nMain.scalaを編集します。ここではJSONファイルを単語集計したものをテキストファイルに保存するコードを書いていきます。\nimport org.apache.spark.{SparkConf, SparkContext} import com.fasterxml.jackson.databind.ObjectMapper import com.fasterxml.jackson.module.scala.DefaultScalaModule object example { def main(args: Array[String]): Unit = { // Sessionの生成  val conf = new SparkConf().setAppName(\u0026#34;appname\u0026#34;).setMaster(\u0026#34;local[*]\u0026#34;) val sc = new SparkContext(conf) val jsonLines = sc.parallelize(Array( \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Apple\u0026#34;,\u0026#34;num\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Orange\u0026#34;,\u0026#34;num\u0026#34;: 4}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Apple\u0026#34;,\u0026#34;num\u0026#34;: 2}\u0026#34;\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34; : \u0026#34;Peach\u0026#34;,\u0026#34;num\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34; )) val result = jsonLines.mapPartitions {lines =\u0026gt; //JSONのパーサを初期化  val mapper = new ObjectMapper() mapper.registerModule(DefaultScalaModule) //JSON文字列をパースし、\u0026#34;name\u0026#34;と\u0026#34;num\u0026#34;のペアで返却  lines.map {line =\u0026gt; val f = mapper.readValue(line,classOf[Map[String,String]]) (f(f\u0026#34;name\u0026#34;),f(\u0026#34;num\u0026#34;)) } } // savedirに集計結果を保存  result.saveAsTextFile(\u0026#34;savedir\u0026#34;) } } 実行 Terminal上でjarファイルを生成します。\n$ sbt package spark-submitを使って実行\n$ $SPARK_HOME/bin/spark-submit savedir上に集計結果が保存されていることを確認します。\n$ cat savedir_part* (Apple,1) (Orange,4) (Apple,2) (Peach,1) 終わり 実行毎にspark-submit〜と打つのは煩雑ですが、予測候補が出てくるのは開発する上での嬉しい＆助かる機能です🥰\n","permalink":"https://467tn.com/blog/content2/","tags":["spark","IntelliJIDEA"],"title":"IntelliJ IDEAでのSparkアプリケーション開発方法（Scala編）"},{"categories":["技術"],"contents":"今までpysparkをいじるときはコンソールでネチネチやっていたのですが、 pythonをjupyter-notebookで開発しているときに便利だなあと思ったので、思い切ってpysparkをいじるときもjupyter-notebookを使うようにしました。その時の備忘録。\n前提条件  Sparkがインストールされていること（この記事がわかりやすかったです。) jupyterがインストールされていること(pipまたはcondaでインストール)  環境  OS：Mac python：Python 3.7.6 Spark：2.4.5 jupyter-notebook：6.0.3  Sparkの設定 Spark上の環境ファイルのテンプレート(spark-env-sh.template)をコピーします。\n$ cd $SPARK_HOME/conf $ cp spark-env.sh.template spark-env.sh コピーしたファイルを書き換えていきます。\n$ vim spark-env.sh $ export PYSPARK_PYTHON=/usr/local/bin/python3 #pythonの場所 $ export PYSPARK_DRIVER_PYTHON=jupyter $ export PYSPARK_DRIVER_PYTHON_OPTS=\u0026#34;notebook\u0026#34; 環境変数の設定 以下の環境変数を.bashrc,.bash_profileに書きます。\nvim ~/.bashrc ... SPARK_HOME=#Sparkをインストールした場所 PATH=$SPARK_HOME/bin:$PATH ... 動作確認 早速、jupyterを使って簡単な演算を実装して見ます。\n$ pyspark http://localhost:8888/?token= *Token*が表示されます http://localhost:8888/loginを開きます。表示されたTokenを元にログインします。\nPythonファイルを作ります（New\u0026gt;python3）\n以下のようにsc(SparkSession)が使えていたら完了。\n終わり 快適な開発環境が整いました:heart_eyes:\n","permalink":"https://467tn.com/blog/content1/","tags":["pyspark","jupyter"],"title":"pysparkをjupyter-notebookから使う"}]